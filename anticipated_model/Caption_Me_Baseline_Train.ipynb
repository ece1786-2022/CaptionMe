{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eca7ed2d",
   "metadata": {},
   "source": [
    "# Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbf01e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchtext\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import math\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from mingpt.utils import CfgNode as CN\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ac7cf1",
   "metadata": {},
   "source": [
    "# Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31db5ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path_train = '../All_Data/annotations_train.csv'\n",
    "image_path_train = '../All_Data/train'\n",
    "csv_path_valid = '../All_Data/annotations_valid.csv'\n",
    "image_path_valid = '../All_Data/valid'\n",
    "batch_size = 8\n",
    "epochs = 50\n",
    "n_embed = 100\n",
    "glove = torchtext.vocab.GloVe(name=\"6B\",dim=n_embed) # embedding size = 100  \n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96f09c2",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc46f0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_Dataset(Dataset):\n",
    "    def __init__(self, image_folder_path, vocab, csv_path, custom_transforms):\n",
    "        self.image_folder_path = image_folder_path\n",
    "        annotations = pd.read_csv(csv_path)\n",
    "        self.captions = np.array(annotations['captions'])\n",
    "        self.image_names = np.array(annotations['file_directory'])    \n",
    "        self.custom_transforms = custom_transforms\n",
    "        self.replace_dict = {'Cockapoo':'parrot', 'Dalmation':'dalmatian', 'Bluetick':'bluebonnet', 'Perenees':'pere', 'Groenendael':'goren', 'Shih-Tzu':'shih', 'Shar_Pei':'shar', 'Komondor':'komon'}\n",
    "        self.vocab = vocab\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.captions)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_full_name = self.image_folder_path + '/' + self.image_names[idx]\n",
    "        x = Image.open(image_full_name)\n",
    "        if self.custom_transforms is not None:\n",
    "            x = self.custom_transforms(x)\n",
    "#             x = x.permute(1,2,0)\n",
    "        ground_truth_cap = self.captions[idx]\n",
    "        V = len(self.vocab.vectors)\n",
    "        L = ground_truth_cap.split()\n",
    "        for i, word in enumerate (L):\n",
    "            if word in self.replace_dict.keys():\n",
    "                L[i] = self.replace_dict[word]\n",
    "                \n",
    "        tokenized_caption = torch.tensor([self.vocab.stoi.get(w.lower(), V-1) for w in L])  # Use the last word in the vocab as the \"out-of-vocabulary\" token\n",
    "        if V-1 in tokenized_caption:\n",
    "            print('Wrong Labelling')\n",
    "#         print(image_full_name, ground_truth_cap)        \n",
    "        return x, tokenized_caption\n",
    "    \n",
    "    def get_vocab_size(self):\n",
    "        return len(self.vocab.vectors)  \n",
    "    \n",
    "    def get_block_size(self):\n",
    "        all_captions_len = []\n",
    "        for i in range(len(self.captions)):\n",
    "            all_captions_len.append(len(self.captions[i].split()))\n",
    "        return max(all_captions_len)+1\n",
    "    \n",
    "train_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(224),\n",
    "    torchvision.transforms.RandomHorizontalFlip(p=0.3),\n",
    "    torchvision.transforms.RandomRotation(degrees=10),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "valid_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(224),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "def lm_collate_fn(batch, device):\n",
    "    x = [item[0] for item in batch]  \n",
    "    y_input = [item[1][:-1] for item in batch]  \n",
    "    y_label = [item[1] for item in batch]\n",
    "    maxlen_input = max([len(s) for s in y_input])\n",
    "    maxlen_label = max([len(s) for s in y_label])\n",
    "    padding_value = glove.stoi.get('unk')\n",
    "    #x from first word to the second last word, y from second word to the last word\n",
    "    input_cap, label_cap = [], []\n",
    "    for sy_i, sy_l in zip(y_input, y_label):\n",
    "        input_cap.append(torch.cat([sy_i, torch.ones(maxlen_input - len(sy_i))*padding_value]))\n",
    "        label_cap.append(torch.cat([sy_l, torch.ones(maxlen_label - len(sy_l))*padding_value]))\n",
    "    return torch.stack(x).long().to(device), torch.stack(input_cap).long().to(device), torch.stack(label_cap).long().to(device)\n",
    "  \n",
    "train_dataset = Custom_Dataset(image_path_train, glove, csv_path_train, train_transforms)\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn = lambda batch: lm_collate_fn(batch, device))\n",
    "\n",
    "valid_dataset = Custom_Dataset(image_path_valid, glove, csv_path_valid, valid_transforms)\n",
    "batch_size = 32\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, collate_fn = lambda batch: lm_collate_fn(batch, device))\n",
    "\n",
    "vocab_size = train_dataset.get_vocab_size()\n",
    "block_size = train_dataset.get_block_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b624598",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "018500df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.py\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "class NewGELU(nn.Module):\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (x + 0.044715 * torch.pow(x, 3.0))))\n",
    "\n",
    "class CausalSelfAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.n_embd % config.n_head == 0\n",
    "        # key, query, value projections for all heads, but in a batch\n",
    "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd)\n",
    "        # output projection\n",
    "        self.c_proj = nn.Linear(config.n_embd, config.n_embd)\n",
    "        # regularization\n",
    "        self.attn_dropout = nn.Dropout(config.attn_pdrop)\n",
    "        self.resid_dropout = nn.Dropout(config.resid_pdrop)\n",
    "        # causal mask to ensure that attention is only applied to the left in the input sequence\n",
    "        self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
    "                                     .view(1, 1, config.block_size, config.block_size))\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.n_embd\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n",
    "\n",
    "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
    "        q, k ,v  = self.c_attn(x).split(self.n_embd, dim=2)\n",
    "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "\n",
    "        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n",
    "        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
    "        att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n",
    "        att = F.softmax(att, dim=-1)\n",
    "        att = self.attn_dropout(att)\n",
    "        y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n",
    "\n",
    "        # output projection\n",
    "        y = self.resid_dropout(self.c_proj(y))\n",
    "        return y\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln_1 = nn.LayerNorm(config.n_embd)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.ln_2 = nn.LayerNorm(config.n_embd)\n",
    "        self.mlp = nn.ModuleDict(dict(\n",
    "            c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd),\n",
    "            c_proj  = nn.Linear(4 * config.n_embd, config.n_embd),\n",
    "            act     = NewGELU(),\n",
    "            dropout = nn.Dropout(config.resid_pdrop),\n",
    "        ))\n",
    "        m = self.mlp\n",
    "        self.mlpf = lambda x: m.dropout(m.c_proj(m.act(m.c_fc(x)))) # MLP forward\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x.shape = (batch, sent len, embedding)\n",
    "        x = x + self.attn(self.ln_1(x))\n",
    "        x = x + self.mlpf(self.ln_2(x))\n",
    "        return x\n",
    "\n",
    "class GPT(nn.Module):\n",
    "    \"\"\" GPT Language Model \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def get_default_config():\n",
    "        C = CN()\n",
    "        # either model_type or (n_layer, n_head, n_embd) must be given in the config\n",
    "        C.model_type = 'gpt'\n",
    "        C.n_layer = None\n",
    "        C.n_head = None\n",
    "        C.n_embd =  None\n",
    "        # these options must be filled in externally\n",
    "        C.vocab_size = None\n",
    "        C.block_size = None\n",
    "        # dropout hyperparameters\n",
    "        C.embd_pdrop = 0.1\n",
    "        C.resid_pdrop = 0.1\n",
    "        C.attn_pdrop = 0.1\n",
    "        return C\n",
    "\n",
    "    def __init__(self, config, vocab):\n",
    "        super().__init__()\n",
    "        assert config.vocab_size is not None\n",
    "        assert config.block_size is not None\n",
    "        self.block_size = config.block_size\n",
    "\n",
    "        type_given = config.model_type is not None\n",
    "        params_given = all([config.n_layer is not None, config.n_head is not None, config.n_embd is not None])\n",
    "        assert type_given ^ params_given # exactly one of these (XOR)\n",
    "        if type_given:\n",
    "            # translate from model_type to detailed configuration\n",
    "            config.merge_from_dict({\n",
    "                # names follow the huggingface naming conventions\n",
    "                # GPT-1\n",
    "                'openai-gpt':   dict(n_layer=12, n_head=12, n_embd=768),  # 117M params\n",
    "                # GPT-2 configs\n",
    "                'gpt2':         dict(n_layer=12, n_head=12, n_embd=768),  # 124M params\n",
    "                'gpt2-medium':  dict(n_layer=24, n_head=16, n_embd=1024), # 350M params\n",
    "                'gpt2-large':   dict(n_layer=36, n_head=20, n_embd=1280), # 774M params\n",
    "                'gpt2-xl':      dict(n_layer=48, n_head=25, n_embd=1600), # 1558M params\n",
    "                # Gophers\n",
    "                'gopher-44m':   dict(n_layer=8, n_head=16, n_embd=512),\n",
    "                # (there are a number more...)\n",
    "                # I made these tiny models up\n",
    "                'gpt-mini':     dict(n_layer=5, n_head=5, n_embd=n_embed),\n",
    "                'gpt-micro':    dict(n_layer=4, n_head=4, n_embd=128),\n",
    "                'gpt-nano':     dict(n_layer=3, n_head=3, n_embd=48),\n",
    "            }[config.model_type])\n",
    "\n",
    "        #wte is embedding for words\n",
    "        #wpe is embedding for positions\n",
    "        self.transformer = nn.ModuleDict(dict(\n",
    "            wte = nn.Embedding.from_pretrained(vocab.vectors, freeze = True),\n",
    "            wpe = nn.Embedding(config.block_size, config.n_embd),\n",
    "            drop = nn.Dropout(config.embd_pdrop),\n",
    "            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
    "            ln_f = nn.LayerNorm(config.n_embd),\n",
    "        ))\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "\n",
    "        # init all weights, and apply a special scaled init to the residual projections, per GPT-2 paper\n",
    "        self.apply(self._init_weights)\n",
    "        for pn, p in self.named_parameters():\n",
    "            if pn.endswith('c_proj.weight'):\n",
    "                torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2 * config.n_layer))\n",
    "\n",
    "        # report number of parameters (note we don't count the decoder parameters in lm_head)\n",
    "        n_params = sum(p.numel() for p in self.transformer.parameters())\n",
    "        print(\"number of parameters: %.2fM\" % (n_params/1e6,))\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            torch.nn.init.zeros_(module.bias)\n",
    "            torch.nn.init.ones_(module.weight)\n",
    "\n",
    "    def configure_optimizers(self, train_config, cnn_model_params):\n",
    "        # separate out all parameters to those that will and won't experience regularizing weight decay\n",
    "        decay = set()\n",
    "        no_decay = set()\n",
    "        whitelist_weight_modules = (torch.nn.Linear, )\n",
    "        blacklist_weight_modules = (torch.nn.LayerNorm, torch.nn.Embedding)\n",
    "        for mn, m in self.named_modules():\n",
    "            for pn, p in m.named_parameters():\n",
    "                fpn = '%s.%s' % (mn, pn) if mn else pn # full param name\n",
    "                # random note: because named_modules and named_parameters are recursive\n",
    "                # we will see the same tensors p many many times. but doing it this way\n",
    "                # allows us to know which parent module any tensor p belongs to...\n",
    "                if pn.endswith('bias'):\n",
    "                    # all biases will not be decayed\n",
    "                    no_decay.add(fpn)\n",
    "                elif pn.endswith('weight') and isinstance(m, whitelist_weight_modules):\n",
    "                    # weights of whitelist modules will be weight decayed\n",
    "                    decay.add(fpn)\n",
    "                elif pn.endswith('weight') and isinstance(m, blacklist_weight_modules):\n",
    "                    # weights of blacklist modules will NOT be weight decayed\n",
    "                    no_decay.add(fpn)\n",
    "\n",
    "        # validate that we considered every parameter\n",
    "        param_dict = {pn: p for pn, p in self.named_parameters()}\n",
    "        inter_params = decay & no_decay\n",
    "        union_params = decay | no_decay\n",
    "        assert len(inter_params) == 0, \"parameters %s made it into both decay/no_decay sets!\" % (str(inter_params), )\n",
    "        assert len(param_dict.keys() - union_params) == 0, \"parameters %s were not separated into either decay/no_decay set!\" \\\n",
    "                                                    % (str(param_dict.keys() - union_params), )\n",
    "        if cnn_model_params is not None:\n",
    "            # create the pytorch optimizer object\n",
    "            optim_groups = [\n",
    "                {\"params\": [param_dict[pn] for pn in sorted(list(decay))], \"weight_decay\": train_config.weight_decay},\n",
    "                {\"params\": [param_dict[pn] for pn in sorted(list(no_decay))], \"weight_decay\": 0.0},\n",
    "                {\"params\": cnn_model_params,'lr': 3e-5}\n",
    "            ]\n",
    "            \n",
    "            n_parameters_transformer = sum(p.numel()\n",
    "               for p in self.parameters() if p.requires_grad)\n",
    "            n_parameters_cnn = sum(p.numel()\n",
    "                           for p in cnn_model_params if p.requires_grad)\n",
    "            print(f\"Number of trainable params: {n_parameters_transformer + n_parameters_cnn}\")\n",
    "        else:\n",
    "            # create the pytorch optimizer object\n",
    "            optim_groups = [\n",
    "                {\"params\": [param_dict[pn] for pn in sorted(list(decay))], \"weight_decay\": train_config.weight_decay},\n",
    "                {\"params\": [param_dict[pn] for pn in sorted(list(no_decay))], \"weight_decay\": 0.0}\n",
    "            ]  \n",
    "        \n",
    "            n_parameters_transformer = sum(p.numel()\n",
    "                           for p in self.parameters() if p.requires_grad)\n",
    "            print(f\"Number of trainable params: {n_parameters_transformer}\")\n",
    "        \n",
    "        optimizer = torch.optim.AdamW(optim_groups, lr=train_config.learning_rate, betas=train_config.betas)\n",
    "        return optimizer\n",
    "\n",
    "    def forward(self, image_embed, idx=None, targets=None, finetune_classify=False):\n",
    "\n",
    "        device = image_embed.device\n",
    "  \n",
    "        if idx is not None:\n",
    "            b, t = idx.size()\n",
    "            assert t <= self.block_size, f\"Cannot forwarnd sequence of length {t}, block size is only {self.block_size}\"\n",
    "            pos = torch.arange(0, t+1, dtype=torch.long, device=device).unsqueeze(0) # shape (1, t)\n",
    "\n",
    "            # forward the GPT model itself\n",
    "            tok_emb = self.transformer.wte(idx) # token embeddings of shape (b, t, n_embd)\n",
    "            tok_emb = torch.cat((image_embed.unsqueeze(1), tok_emb), 1)\n",
    "          \n",
    "        else:\n",
    "            pos = torch.arange(0, 1, dtype=torch.long, device=device).unsqueeze(0) # shape (1, t)\n",
    "            tok_emb = image_embed.unsqueeze(1)   \n",
    "        pos_emb = self.transformer.wpe(pos) # position embeddings of shape (1, t, n_embd)\n",
    "        \n",
    "        assert tok_emb[0].shape == pos_emb[0].shape, f\"wrong token or position embedding\"\n",
    "        x = self.transformer.drop(tok_emb + pos_emb)\n",
    "        for block in self.transformer.h:\n",
    "            x = block(x)\n",
    "        x = self.transformer.ln_f(x)\n",
    "        #x.shape = (batch, sentence len, embedding)\n",
    "        if not finetune_classify:\n",
    "            # LM forward procedure\n",
    "            logits = self.lm_head(x)\n",
    "        else:\n",
    "            # Finetune classify procedure\n",
    "            print('error')\n",
    "            return\n",
    "            \n",
    "        # if we are given some desired targets also calculate the loss\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
    "        return logits, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dbf39fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 40.61M\n"
     ]
    }
   ],
   "source": [
    "# set up model configurations\n",
    "model_config = GPT.get_default_config()\n",
    "model_config.model_type = 'gpt-mini'\n",
    "model_config.vocab_size = vocab_size\n",
    "#block_size is a max sentence length in dataset\n",
    "model_config.block_size = block_size\n",
    "model = GPT(model_config, glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d25c008",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fca9c92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "\n",
    "    @staticmethod\n",
    "    def get_default_config():\n",
    "        C = CN()\n",
    "        # device to train on\n",
    "        C.device = 'auto'\n",
    "        # dataloder parameters\n",
    "        C.num_workers = 4\n",
    "        # optimizer parameters\n",
    "        C.max_iters = None\n",
    "        C.batch_size = 64\n",
    "        C.learning_rate = 3e-4\n",
    "        C.betas = (0.9, 0.95)\n",
    "        C.weight_decay = 0.1 # only applied on matmul weights\n",
    "        C.grad_norm_clip = 1.0\n",
    "        return C\n",
    "\n",
    "    def __init__(self, config, model, train_loader, valid_loader, epochs, downstream_finetune = False):\n",
    "        self.config = config\n",
    "        self.model = model\n",
    "        self.optimizer = None\n",
    "        self.train_loader = train_loader\n",
    "        self.valid_loader = valid_loader\n",
    "        self.epochs = epochs\n",
    "        self.callbacks = defaultdict(list)\n",
    "        self.downstream_finetune = False\n",
    "        # determine the device we'll train on\n",
    "        if config.device == 'auto':\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = config.device\n",
    "        self.model = self.model.to(self.device)\n",
    "        print(\"running on device\", self.device)\n",
    "\n",
    "        # variables that will be assigned to trainer class later for logging and etc\n",
    "        self.iter_time = 0.0\n",
    "        self.iter_dt = 0.0\n",
    "\n",
    "    def add_callback(self, onevent: str, callback):\n",
    "        self.callbacks[onevent].append(callback)\n",
    "\n",
    "    def set_callback(self, onevent: str, callback):\n",
    "        self.callbacks[onevent] = [callback]\n",
    "\n",
    "    def trigger_callbacks(self, onevent: str):\n",
    "        for callback in self.callbacks.get(onevent, []):\n",
    "            callback(self)\n",
    "\n",
    "    def run(self):\n",
    "        model, config = self.model, self.config\n",
    "        cnn_model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=True,)\n",
    "        for param in cnn_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        cnn_model.classifier = nn.Sequential(nn.Linear(1280, 512),\n",
    "                                            nn.ReLU(),\n",
    "                                            nn.Dropout(0.2),\n",
    "                                            nn.Linear(512, n_embed))\n",
    "        cnn_model = cnn_model.to(device)\n",
    "        # setup the optimizer\n",
    "        self.optimizer = model.configure_optimizers(config, cnn_model.parameters())\n",
    "        train_loss_set = []\n",
    "        valid_loss_set = []\n",
    "        # setup the dataloader     \n",
    "        for epoch in range(self.epochs):\n",
    "            print('Epoch ' + str(epoch) + ':')\n",
    "            model.train()\n",
    "            cnn_model.train()\n",
    "            train_loss_epoch = []\n",
    "            \n",
    "            with tqdm.tqdm(total=len(self.train_loader)) as pbar:\n",
    "                #train model and calculate training loss\n",
    "                for x, y_input, y_label in self.train_loader:\n",
    "                    # forward the model\n",
    "                    x = x.type(torch.FloatTensor).to(device)\n",
    "                    image_embed = cnn_model(x)\n",
    "                    logits, self.loss = model(image_embed.to(self.device), y_input, y_label, self.downstream_finetune)\n",
    "                    train_loss_epoch.append(self.loss.detach().cpu().item())\n",
    "\n",
    "                    # backprop and update the parameters\n",
    "                    model.zero_grad(set_to_none=True)\n",
    "                    self.loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), config.grad_norm_clip)\n",
    "                    self.optimizer.step()\n",
    "                    pbar.update(1)\n",
    "                    del x, y_input, y_label\n",
    "\n",
    "                print('Training Loss is : {}'.format(sum(train_loss_epoch)/len(train_loss_epoch)))\n",
    "                train_loss_set.append(sum(train_loss_epoch)/len(train_loss_epoch))\n",
    "            \n",
    "            print('start_validation')    \n",
    "            model.eval()\n",
    "            cnn_model.eval()  \n",
    "            valid_loss_epoch = []\n",
    "            for x, y_input, y_label in self.valid_loader:\n",
    "                # forward the model\n",
    "                x = x.type(torch.FloatTensor).to(device)\n",
    "                image_embed = cnn_model(x)\n",
    "                logits, loss = model(image_embed.to(self.device), y_input, y_label, self.downstream_finetune)\n",
    "                valid_loss_epoch.append(loss.detach().cpu().item())\n",
    "                del x, y_input, y_label\n",
    "                \n",
    "            current_valid_loss = sum(valid_loss_epoch)/len(valid_loss_epoch)\n",
    "            print('Validation Loss is : {}'.format(current_valid_loss))              \n",
    "            \n",
    "            #save the checkpoint if the current validation loss is better than all previous epochs   \n",
    "            if len(valid_loss_set) > 0 and current_valid_loss < min(valid_loss_set):\n",
    "                torch.save(model.state_dict(), './saved_checkpoints/best_transformer.pt')\n",
    "                torch.save(cnn_model.state_dict(), './saved_checkpoints/best_cnn.pt')\n",
    "                print('saving checkpoints')\n",
    "            #stop training if the validation loss increases for two consecutive epochs     \n",
    "            if len(valid_loss_set) > 2 and current_valid_loss > valid_loss_set[-1] and valid_loss_set[-1] > valid_loss_set[-2]:\n",
    "                valid_loss_set.append(current_valid_loss)  \n",
    "                break           \n",
    "            else:\n",
    "                valid_loss_set.append(current_valid_loss)\n",
    "        \n",
    "        return train_loss_set, valid_loss_set, epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6e29acb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\zixua/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on device cuda\n",
      "Number of trainable params: 41315572\n",
      "Epoch 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:23<00:00,  5.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 8.632085637348455\n",
      "start_validation\n",
      "Validation Loss is : 4.99385831091139\n",
      "Epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:18<00:00,  6.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 2.5657225982929632\n",
      "start_validation\n",
      "Validation Loss is : 1.2247742745611403\n",
      "saving checkpoints\n",
      "Epoch 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:18<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.9278073698524537\n",
      "start_validation\n",
      "Validation Loss is : 0.7973378201325735\n",
      "saving checkpoints\n",
      "Epoch 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:17<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.6915542085965475\n",
      "start_validation\n",
      "Validation Loss is : 0.6879064440727234\n",
      "saving checkpoints\n",
      "Epoch 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:17<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.6187067060935788\n",
      "start_validation\n",
      "Validation Loss is : 0.6448976049820582\n",
      "saving checkpoints\n",
      "Epoch 5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:18<00:00,  6.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.5830396442878537\n",
      "start_validation\n",
      "Validation Loss is : 0.6238336000177596\n",
      "saving checkpoints\n",
      "Epoch 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:18<00:00,  6.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.5578798375478605\n",
      "start_validation\n",
      "Validation Loss is : 0.6136139548487134\n",
      "saving checkpoints\n",
      "Epoch 7:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:18<00:00,  6.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.543054368195495\n",
      "start_validation\n",
      "Validation Loss is : 0.5986444072590934\n",
      "saving checkpoints\n",
      "Epoch 8:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:18<00:00,  6.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.5318431866362812\n",
      "start_validation\n",
      "Validation Loss is : 0.5935651179816988\n",
      "saving checkpoints\n",
      "Epoch 9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:18<00:00,  6.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.5268043669743266\n",
      "start_validation\n",
      "Validation Loss is : 0.5932991703351339\n",
      "saving checkpoints\n",
      "Epoch 10:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:18<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.5186979101925362\n",
      "start_validation\n",
      "Validation Loss is : 0.5957943002382914\n",
      "Epoch 11:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:18<00:00,  6.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.5152365027404413\n",
      "start_validation\n",
      "Validation Loss is : 0.5899711102247238\n",
      "saving checkpoints\n",
      "Epoch 12:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:18<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.5082714581877236\n",
      "start_validation\n",
      "Validation Loss is : 0.581805396411154\n",
      "saving checkpoints\n",
      "Epoch 13:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:18<00:00,  6.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.5094615761342087\n",
      "start_validation\n",
      "Validation Loss is : 0.5900936540630128\n",
      "Epoch 14:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:18<00:00,  6.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.5049154903830552\n",
      "start_validation\n",
      "Validation Loss is : 0.5840010427766376\n",
      "Epoch 15:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:18<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.5013377382987882\n",
      "start_validation\n",
      "Validation Loss is : 0.5771534012423621\n",
      "saving checkpoints\n",
      "Epoch 16:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:18<00:00,  6.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.49631730545827046\n",
      "start_validation\n",
      "Validation Loss is : 0.5843211809794108\n",
      "Epoch 17:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:20<00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.4957000104392447\n",
      "start_validation\n",
      "Validation Loss is : 0.5782089117500517\n",
      "Epoch 18:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:18<00:00,  6.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.4974657287442587\n",
      "start_validation\n",
      "Validation Loss is : 0.5803424235847261\n",
      "Epoch 19:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:19<00:00,  6.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.49083029569649117\n",
      "start_validation\n",
      "Validation Loss is : 0.5814288142654631\n"
     ]
    }
   ],
   "source": [
    "#start training\n",
    "train_config = Trainer.get_default_config()\n",
    "trainer = Trainer(train_config, model, train_loader, valid_loader, epochs, downstream_finetune = False)\n",
    "\n",
    "# Train!\n",
    "train_loss_set, valid_loss_set, epoch = trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1dea6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot results\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18,8))\n",
    "epoch_values = list(range(0, epoch+1, 1))\n",
    "\n",
    "ax1.plot(epoch_values, train_loss_set)\n",
    "ax2.plot(epoch_values, valid_loss_set)\n",
    "\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Average Train Loss')    \n",
    "ax1.set_title('Average Train Loss vs. Epochs')\n",
    "\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Average Validation Loss')    \n",
    "ax2.set_title('Average Validation Loss vs. Epochs')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8574dc33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
