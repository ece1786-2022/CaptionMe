{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f14cb8ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\zixua/.cache\\torch\\hub\\saahiluppal_catr_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a blue and white siting american hairless dog in the blank background\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from transformers import BertTokenizer\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import numpy as np\n",
    "from models import caption\n",
    "from datasets import coco, utils\n",
    "from configuration import Config\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "# parser = argparse.ArgumentParser(description='Image Captioning')\n",
    "# parser.add_argument('--path', type=str, help='path to image', required=True)\n",
    "# parser.add_argument('--v', type=str, help='version', default='v3')\n",
    "# parser.add_argument('--checkpoint', type=str, help='checkpoint path', default=None)\n",
    "# args = parser.parse_args()\n",
    "# image_path = args.path\n",
    "# version = args.v\n",
    "# checkpoint_path = args.checkpoint\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "image_path = '../All_Data/valid/American Hairless/1.jpg'\n",
    "version = 'v3'\n",
    "\n",
    "config = Config()\n",
    "\n",
    "if version == 'v1':\n",
    "    model = torch.hub.load('saahiluppal/catr', 'v1', pretrained=True)\n",
    "elif version == 'v2':\n",
    "    model = torch.hub.load('saahiluppal/catr', 'v2', pretrained=True)\n",
    "elif version == 'v3':\n",
    "    model = torch.hub.load('saahiluppal/catr', 'v3', pretrained=True)\n",
    "    torch.save(model.state_dict(), 'best_model.pt')\n",
    "    model.load_state_dict(torch.load('best_model_fine_tunned.pt'))\n",
    "else:\n",
    "    print(\"Checking for checkpoint.\")\n",
    "    if checkpoint_path is None:\n",
    "        raise NotImplementedError('No model to chose from!')\n",
    "    else:\n",
    "        if not os.path.exists(checkpoint_path):\n",
    "            raise NotImplementedError('Give valid checkpoint path')\n",
    "        print(\"Found checkpoint! Loading!\")\n",
    "        model,_ = caption.build_model(config)\n",
    "        print(\"Loading Checkpoint...\")\n",
    "        checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "        model.load_state_dict(checkpoint['model'])\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "start_token = tokenizer.convert_tokens_to_ids(tokenizer._cls_token)\n",
    "end_token = tokenizer.convert_tokens_to_ids(tokenizer._sep_token)\n",
    "\n",
    "def create_caption_and_mask(start_token, max_length):\n",
    "    caption_template = torch.zeros((1, max_length), dtype=torch.long)\n",
    "    mask_template = torch.ones((1, max_length), dtype=torch.bool)\n",
    "\n",
    "    caption_template[:, 0] = start_token\n",
    "    mask_template[:, 0] = False\n",
    "\n",
    "    return caption_template, mask_template\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(image_path, devic, temperature=1.0, top_p=None, top_k=None):\n",
    "    if top_p is not None and top_k is not None:\n",
    "        print('Only one sampling approach is allowed')\n",
    "        return\n",
    "    if top_p is None and top_k is None:\n",
    "        print('You must select a sampling approach')\n",
    "        return\n",
    "    \n",
    "    image = Image.open(image_path)\n",
    "    image = coco.val_transform(image)\n",
    "    image = image.unsqueeze(0)\n",
    "    generation_prob = []\n",
    "    generation_word = []   \n",
    "    #caption.shape(1, max_length)\n",
    "    caption, cap_mask = create_caption_and_mask(\n",
    "        start_token, config.max_position_embeddings)    \n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    for i in range(config.max_position_embeddings - 1):\n",
    "        #caption, cap_mask = (1,128) 128 is max_length\n",
    "        #prediction.shape = torch.Size([1, 128, 30522])\n",
    "        #image.shape = (1,3,299,299)\n",
    "        predictions = model(image.to(device), caption.to(device), cap_mask.to(device))\n",
    "        predictions = predictions[:, i, :] / temperature\n",
    "        probs = F.softmax(predictions, dim=-1)\n",
    "        if top_k is not None:\n",
    "            idx_next_prob, idx_next = torch.topk(probs, k=top_k, dim=-1)\n",
    "            \n",
    "        if top_p is not None:\n",
    "            top_k = 1\n",
    "            idx_next_prob, idx_next = torch.topk(probs, k=top_k, dim=-1)\n",
    "            while idx_next_prob.detach().cpu().sum().item() < top_p:\n",
    "                top_k += 1\n",
    "                idx_next_prob, idx_next = torch.topk(probs, k=top_k, dim=-1)\n",
    "        \n",
    "        idx_next_prob, idx_next = idx_next_prob[0].detach().cpu(), idx_next[0].detach().cpu()\n",
    "        sum_prob = idx_next_prob.sum().item()\n",
    "        idx_next_prob = [prob_i/sum_prob for prob_i in idx_next_prob.tolist()]\n",
    "        idx_next_prob[-1] = 1 - sum(idx_next_prob[:-1]) \n",
    "        if idx_next_prob[-1] < 0:\n",
    "            idx_next_prob[-1] = 0\n",
    "            index = -1\n",
    "            while sum(idx_next_prob[:index]) > 1:\n",
    "                idx_next_prob[index-1] = 0\n",
    "                index -= 1\n",
    "            idx_next_prob [index] = 1 - sum(idx_next_prob[:index])\n",
    "\n",
    "        select_token = np.random.choice(idx_next.tolist(), 1, p=idx_next_prob)  \n",
    "        for token, token_prob in zip(idx_next, idx_next_prob):\n",
    "            if token == select_token[0]:\n",
    "                generation_prob.append(token_prob)    \n",
    "            \n",
    "        generation_word.append(tokenizer.decode(select_token.tolist(), skip_special_tokens=True))        \n",
    "        \n",
    "        predicted_id = torch.argmax(predictions, axis=-1)\n",
    "        if select_token[0] == 102 or select_token[0] == 1012:\n",
    "            return caption, generation_word, generation_prob\n",
    "\n",
    "        caption[:, i+1] = select_token[0]\n",
    "        cap_mask[:, i+1] = False\n",
    "        \n",
    "    return caption, generation_word, generation_prob\n",
    "\n",
    "output, generation_word, generation_prob = evaluate(image_path, device, temperature=1.0, top_p=None, top_k=3)\n",
    "result = tokenizer.decode(output[0].tolist(), skip_special_tokens=True)\n",
    "#result = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(result.capitalize())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab990d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fe75f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
