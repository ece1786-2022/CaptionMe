{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eca7ed2d",
   "metadata": {},
   "source": [
    "# Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbf01e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchtext\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import math\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from mingpt.utils import CfgNode as CN\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ac7cf1",
   "metadata": {},
   "source": [
    "# Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31db5ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path_train = '../All_Data/annotations_train.csv'\n",
    "image_path_train = '../All_Data/train'\n",
    "csv_path_valid = '../All_Data/annotations_valid.csv'\n",
    "image_path_valid = '../All_Data/valid'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 8\n",
    "epochs = 50\n",
    "n_embed = 100\n",
    "glove = torchtext.vocab.GloVe(name=\"6B\",dim=n_embed) # embedding size = 100  \n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96f09c2",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc46f0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_Dataset(Dataset):\n",
    "    def __init__(self, image_folder_path, vocab, csv_path, custom_transforms):\n",
    "        self.image_folder_path = image_folder_path\n",
    "        annotations = pd.read_csv(csv_path)\n",
    "        self.captions = np.array(annotations['captions'])\n",
    "        self.image_names = np.array(annotations['file_directory'])    \n",
    "        self.custom_transforms = custom_transforms\n",
    "        self.replace_dict = {'Cockapoo':'parrot', 'Dalmation':'dalmatian', 'Bluetick':'bluebonnet', 'Perenees':'pere', 'Groenendael':'goren', 'Shih-Tzu':'shih', 'Shar_Pei':'shar', 'Komondor':'komon'}\n",
    "        self.vocab = vocab\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.captions)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_full_name = self.image_folder_path + '/' + self.image_names[idx]\n",
    "        x = Image.open(image_full_name)\n",
    "        if self.custom_transforms is not None:\n",
    "            x = self.custom_transforms(x)\n",
    "#             x = x.permute(1,2,0)\n",
    "        ground_truth_cap = self.captions[idx]\n",
    "        V = len(self.vocab.vectors)\n",
    "        L = ground_truth_cap.split()\n",
    "        for i, word in enumerate (L):\n",
    "            if word in self.replace_dict.keys():\n",
    "                L[i] = self.replace_dict[word]\n",
    "                \n",
    "        tokenized_caption = torch.tensor([self.vocab.stoi.get(w.lower(), V-1) for w in L])  # Use the last word in the vocab as the \"out-of-vocabulary\" token\n",
    "        if V-1 in tokenized_caption:\n",
    "            print('Wrong Labelling')\n",
    "#         print(image_full_name, ground_truth_cap)        \n",
    "        return x, tokenized_caption\n",
    "    \n",
    "    def get_vocab_size(self):\n",
    "        return len(self.vocab.vectors)  \n",
    "    \n",
    "    def get_block_size(self):\n",
    "        all_captions_len = []\n",
    "        for i in range(len(self.captions)):\n",
    "            all_captions_len.append(len(self.captions[i].split()))\n",
    "        return max(all_captions_len)+1\n",
    "    \n",
    "train_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(224),\n",
    "    torchvision.transforms.RandomHorizontalFlip(p=0.3),\n",
    "    torchvision.transforms.RandomRotation(degrees=10),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "valid_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(224),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "def lm_collate_fn(batch, device):\n",
    "    x = [item[0] for item in batch]  \n",
    "    y_input = [item[1][:-1] for item in batch]  \n",
    "    y_label = [item[1] for item in batch]\n",
    "    maxlen_input = max([len(s) for s in y_input])\n",
    "    maxlen_label = max([len(s) for s in y_label])\n",
    "    padding_value = glove.stoi.get('unk')\n",
    "    #x from first word to the second last word, y from second word to the last word\n",
    "    input_cap, label_cap = [], []\n",
    "    for sy_i, sy_l in zip(y_input, y_label):\n",
    "        input_cap.append(torch.cat([sy_i, torch.ones(maxlen_input - len(sy_i))*padding_value]))\n",
    "        label_cap.append(torch.cat([sy_l, torch.ones(maxlen_label - len(sy_l))*padding_value]))\n",
    "    return torch.stack(x).long().to(device), torch.stack(input_cap).long().to(device), torch.stack(label_cap).long().to(device)\n",
    "  \n",
    "train_dataset = Custom_Dataset(image_path_train, glove, csv_path_train, train_transforms)\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn = lambda batch: lm_collate_fn(batch, device))\n",
    "\n",
    "valid_dataset = Custom_Dataset(image_path_valid, glove, csv_path_valid, valid_transforms)\n",
    "batch_size = 32\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, collate_fn = lambda batch: lm_collate_fn(batch, device))\n",
    "\n",
    "vocab_size = train_dataset.get_vocab_size()\n",
    "block_size = train_dataset.get_block_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b624598",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "018500df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.py\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "class NewGELU(nn.Module):\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (x + 0.044715 * torch.pow(x, 3.0))))\n",
    "\n",
    "class CausalSelfAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.n_embd % config.n_head == 0\n",
    "        # key, query, value projections for all heads, but in a batch\n",
    "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd)\n",
    "        # output projection\n",
    "        self.c_proj = nn.Linear(config.n_embd, config.n_embd)\n",
    "        # regularization\n",
    "        self.attn_dropout = nn.Dropout(config.attn_pdrop)\n",
    "        self.resid_dropout = nn.Dropout(config.resid_pdrop)\n",
    "        # causal mask to ensure that attention is only applied to the left in the input sequence\n",
    "        self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
    "                                     .view(1, 1, config.block_size, config.block_size))\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.n_embd\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n",
    "\n",
    "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
    "        q, k ,v  = self.c_attn(x).split(self.n_embd, dim=2)\n",
    "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "\n",
    "        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n",
    "        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
    "        att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n",
    "        att = F.softmax(att, dim=-1)\n",
    "        att = self.attn_dropout(att)\n",
    "        y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n",
    "\n",
    "        # output projection\n",
    "        y = self.resid_dropout(self.c_proj(y))\n",
    "        return y\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln_1 = nn.LayerNorm(config.n_embd)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.ln_2 = nn.LayerNorm(config.n_embd)\n",
    "        self.mlp = nn.ModuleDict(dict(\n",
    "            c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd),\n",
    "            c_proj  = nn.Linear(4 * config.n_embd, config.n_embd),\n",
    "            act     = NewGELU(),\n",
    "            dropout = nn.Dropout(config.resid_pdrop),\n",
    "        ))\n",
    "        m = self.mlp\n",
    "        self.mlpf = lambda x: m.dropout(m.c_proj(m.act(m.c_fc(x)))) # MLP forward\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x.shape = (batch, sent len, embedding)\n",
    "        x = x + self.attn(self.ln_1(x))\n",
    "        x = x + self.mlpf(self.ln_2(x))\n",
    "        return x\n",
    "\n",
    "class GPT(nn.Module):\n",
    "    \"\"\" GPT Language Model \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def get_default_config():\n",
    "        C = CN()\n",
    "        # either model_type or (n_layer, n_head, n_embd) must be given in the config\n",
    "        C.model_type = 'gpt'\n",
    "        C.n_layer = None\n",
    "        C.n_head = None\n",
    "        C.n_embd =  None\n",
    "        # these options must be filled in externally\n",
    "        C.vocab_size = None\n",
    "        C.block_size = None\n",
    "        # dropout hyperparameters\n",
    "        C.embd_pdrop = 0.1\n",
    "        C.resid_pdrop = 0.1\n",
    "        C.attn_pdrop = 0.1\n",
    "        return C\n",
    "\n",
    "    def __init__(self, config, vocab):\n",
    "        super().__init__()\n",
    "        assert config.vocab_size is not None\n",
    "        assert config.block_size is not None\n",
    "        self.block_size = config.block_size\n",
    "\n",
    "        type_given = config.model_type is not None\n",
    "        params_given = all([config.n_layer is not None, config.n_head is not None, config.n_embd is not None])\n",
    "        assert type_given ^ params_given # exactly one of these (XOR)\n",
    "        if type_given:\n",
    "            # translate from model_type to detailed configuration\n",
    "            config.merge_from_dict({\n",
    "                # names follow the huggingface naming conventions\n",
    "                # GPT-1\n",
    "                'openai-gpt':   dict(n_layer=12, n_head=12, n_embd=768),  # 117M params\n",
    "                # GPT-2 configs\n",
    "                'gpt2':         dict(n_layer=12, n_head=12, n_embd=768),  # 124M params\n",
    "                'gpt2-medium':  dict(n_layer=24, n_head=16, n_embd=1024), # 350M params\n",
    "                'gpt2-large':   dict(n_layer=36, n_head=20, n_embd=1280), # 774M params\n",
    "                'gpt2-xl':      dict(n_layer=48, n_head=25, n_embd=1600), # 1558M params\n",
    "                # Gophers\n",
    "                'gopher-44m':   dict(n_layer=8, n_head=16, n_embd=512),\n",
    "                # (there are a number more...)\n",
    "                # I made these tiny models up\n",
    "                'gpt-mini':     dict(n_layer=5, n_head=5, n_embd=n_embed),\n",
    "                'gpt-micro':    dict(n_layer=4, n_head=4, n_embd=128),\n",
    "                'gpt-nano':     dict(n_layer=3, n_head=3, n_embd=48),\n",
    "            }[config.model_type])\n",
    "\n",
    "        #wte is embedding for words\n",
    "        #wpe is embedding for positions\n",
    "        self.transformer = nn.ModuleDict(dict(\n",
    "            wte = nn.Embedding.from_pretrained(vocab.vectors, freeze = True),\n",
    "            wpe = nn.Embedding(config.block_size, config.n_embd),\n",
    "            drop = nn.Dropout(config.embd_pdrop),\n",
    "            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
    "            ln_f = nn.LayerNorm(config.n_embd),\n",
    "        ))\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "\n",
    "        # init all weights, and apply a special scaled init to the residual projections, per GPT-2 paper\n",
    "        self.apply(self._init_weights)\n",
    "        for pn, p in self.named_parameters():\n",
    "            if pn.endswith('c_proj.weight'):\n",
    "                torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2 * config.n_layer))\n",
    "\n",
    "        # report number of parameters (note we don't count the decoder parameters in lm_head)\n",
    "        n_params = sum(p.numel() for p in self.transformer.parameters())\n",
    "        print(\"number of parameters: %.2fM\" % (n_params/1e6,))\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            torch.nn.init.zeros_(module.bias)\n",
    "            torch.nn.init.ones_(module.weight)\n",
    "\n",
    "    def configure_optimizers(self, train_config, cnn_model_params):\n",
    "        # separate out all parameters to those that will and won't experience regularizing weight decay\n",
    "        decay = set()\n",
    "        no_decay = set()\n",
    "        whitelist_weight_modules = (torch.nn.Linear, )\n",
    "        blacklist_weight_modules = (torch.nn.LayerNorm, torch.nn.Embedding)\n",
    "        for mn, m in self.named_modules():\n",
    "            for pn, p in m.named_parameters():\n",
    "                fpn = '%s.%s' % (mn, pn) if mn else pn # full param name\n",
    "                # random note: because named_modules and named_parameters are recursive\n",
    "                # we will see the same tensors p many many times. but doing it this way\n",
    "                # allows us to know which parent module any tensor p belongs to...\n",
    "                if pn.endswith('bias'):\n",
    "                    # all biases will not be decayed\n",
    "                    no_decay.add(fpn)\n",
    "                elif pn.endswith('weight') and isinstance(m, whitelist_weight_modules):\n",
    "                    # weights of whitelist modules will be weight decayed\n",
    "                    decay.add(fpn)\n",
    "                elif pn.endswith('weight') and isinstance(m, blacklist_weight_modules):\n",
    "                    # weights of blacklist modules will NOT be weight decayed\n",
    "                    no_decay.add(fpn)\n",
    "\n",
    "        # validate that we considered every parameter\n",
    "        param_dict = {pn: p for pn, p in self.named_parameters()}\n",
    "        inter_params = decay & no_decay\n",
    "        union_params = decay | no_decay\n",
    "        assert len(inter_params) == 0, \"parameters %s made it into both decay/no_decay sets!\" % (str(inter_params), )\n",
    "        assert len(param_dict.keys() - union_params) == 0, \"parameters %s were not separated into either decay/no_decay set!\" \\\n",
    "                                                    % (str(param_dict.keys() - union_params), )\n",
    "        if cnn_model_params is not None:\n",
    "            # create the pytorch optimizer object\n",
    "            optim_groups = [\n",
    "                {\"params\": [param_dict[pn] for pn in sorted(list(decay))], \"weight_decay\": train_config.weight_decay},\n",
    "                {\"params\": [param_dict[pn] for pn in sorted(list(no_decay))], \"weight_decay\": 0.0},\n",
    "                {\"params\": cnn_model_params,'lr': 3e-5}\n",
    "            ]\n",
    "            \n",
    "            n_parameters_transformer = sum(p.numel()\n",
    "               for p in self.parameters() if p.requires_grad)\n",
    "            n_parameters_cnn = sum(p.numel()\n",
    "                           for p in cnn_model_params if p.requires_grad)\n",
    "            print(f\"Number of trainable params: {n_parameters_transformer + n_parameters_cnn}\")\n",
    "        else:\n",
    "            # create the pytorch optimizer object\n",
    "            optim_groups = [\n",
    "                {\"params\": [param_dict[pn] for pn in sorted(list(decay))], \"weight_decay\": train_config.weight_decay},\n",
    "                {\"params\": [param_dict[pn] for pn in sorted(list(no_decay))], \"weight_decay\": 0.0}\n",
    "            ]  \n",
    "        \n",
    "            n_parameters_transformer = sum(p.numel()\n",
    "                           for p in self.parameters() if p.requires_grad)\n",
    "            print(f\"Number of trainable params: {n_parameters_transformer}\")\n",
    "        \n",
    "        optimizer = torch.optim.AdamW(optim_groups, lr=train_config.learning_rate, betas=train_config.betas)\n",
    "        return optimizer\n",
    "\n",
    "    def forward(self, image_embed, idx=None, targets=None, finetune_classify=False):\n",
    "\n",
    "        device = image_embed.device\n",
    "  \n",
    "        if idx is not None:\n",
    "            b, t = idx.size()\n",
    "            assert t <= self.block_size, f\"Cannot forwarnd sequence of length {t}, block size is only {self.block_size}\"\n",
    "            pos = torch.arange(0, t+1, dtype=torch.long, device=device).unsqueeze(0) # shape (1, t)\n",
    "\n",
    "            # forward the GPT model itself\n",
    "            tok_emb = self.transformer.wte(idx) # token embeddings of shape (b, t, n_embd)\n",
    "            tok_emb = torch.cat((image_embed.unsqueeze(1), tok_emb), 1)\n",
    "          \n",
    "        else:\n",
    "            pos = torch.arange(0, 1, dtype=torch.long, device=device).unsqueeze(0) # shape (1, t)\n",
    "            tok_emb = image_embed.unsqueeze(1)   \n",
    "        pos_emb = self.transformer.wpe(pos) # position embeddings of shape (1, t, n_embd)\n",
    "        \n",
    "        assert tok_emb[0].shape == pos_emb[0].shape, f\"wrong token or position embedding\"\n",
    "        x = self.transformer.drop(tok_emb + pos_emb)\n",
    "        for block in self.transformer.h:\n",
    "            x = block(x)\n",
    "        x = self.transformer.ln_f(x)\n",
    "        #x.shape = (batch, sentence len, embedding)\n",
    "        if not finetune_classify:\n",
    "            # LM forward procedure\n",
    "            logits = self.lm_head(x)\n",
    "        else:\n",
    "            # Finetune classify procedure\n",
    "            print('error')\n",
    "            return\n",
    "            \n",
    "        # if we are given some desired targets also calculate the loss\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
    "        return logits, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dbf39fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 40.61M\n"
     ]
    }
   ],
   "source": [
    "# set up model configurations\n",
    "model_config = GPT.get_default_config()\n",
    "model_config.model_type = 'gpt-mini'\n",
    "model_config.vocab_size = vocab_size\n",
    "#block_size is a max sentence length in dataset\n",
    "model_config.block_size = block_size\n",
    "model = GPT(model_config, glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d25c008",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fca9c92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "\n",
    "    @staticmethod\n",
    "    def get_default_config():\n",
    "        C = CN()\n",
    "        # device to train on\n",
    "        C.device = 'auto'\n",
    "        # dataloder parameters\n",
    "        C.num_workers = 4\n",
    "        # optimizer parameters\n",
    "        C.max_iters = None\n",
    "        C.batch_size = 64\n",
    "        C.learning_rate = 3e-4\n",
    "        C.betas = (0.9, 0.95)\n",
    "        C.weight_decay = 0.1 # only applied on matmul weights\n",
    "        C.grad_norm_clip = 1.0\n",
    "        return C\n",
    "\n",
    "    def __init__(self, config, model, train_loader, valid_loader, epochs, downstream_finetune = False):\n",
    "        self.config = config\n",
    "        self.model = model\n",
    "        self.optimizer = None\n",
    "        self.train_loader = train_loader\n",
    "        self.valid_loader = valid_loader\n",
    "        self.epochs = epochs\n",
    "        self.callbacks = defaultdict(list)\n",
    "        self.downstream_finetune = False\n",
    "        # determine the device we'll train on\n",
    "        if config.device == 'auto':\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = config.device\n",
    "        self.model = self.model.to(self.device)\n",
    "        print(\"running on device\", self.device)\n",
    "\n",
    "        # variables that will be assigned to trainer class later for logging and etc\n",
    "        self.iter_time = 0.0\n",
    "        self.iter_dt = 0.0\n",
    "\n",
    "    def add_callback(self, onevent: str, callback):\n",
    "        self.callbacks[onevent].append(callback)\n",
    "\n",
    "    def set_callback(self, onevent: str, callback):\n",
    "        self.callbacks[onevent] = [callback]\n",
    "\n",
    "    def trigger_callbacks(self, onevent: str):\n",
    "        for callback in self.callbacks.get(onevent, []):\n",
    "            callback(self)\n",
    "\n",
    "    def run(self):\n",
    "        model, config = self.model, self.config\n",
    "        cnn_model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=True,)\n",
    "        for param in cnn_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        cnn_model.classifier = nn.Sequential(nn.Linear(1280, 512),\n",
    "                                            nn.ReLU(),\n",
    "                                            nn.Dropout(0.2),\n",
    "                                            nn.Linear(512, n_embed))\n",
    "        cnn_model = cnn_model.to(device)\n",
    "        # setup the optimizer\n",
    "        self.optimizer = model.configure_optimizers(config, cnn_model.parameters())\n",
    "        train_loss_set = []\n",
    "        valid_loss_set = []\n",
    "        # setup the dataloader     \n",
    "        for epoch in range(self.epochs):\n",
    "            print('Epoch ' + str(epoch) + ':')\n",
    "            model.train()\n",
    "            cnn_model.train()\n",
    "            train_loss_epoch = []\n",
    "            \n",
    "            with tqdm.tqdm(total=len(self.train_loader)) as pbar:\n",
    "                #train model and calculate training loss\n",
    "                for x, y_input, y_label in self.train_loader:\n",
    "                    # forward the model\n",
    "                    x = x.type(torch.FloatTensor).to(device)\n",
    "                    image_embed = cnn_model(x)\n",
    "                    logits, self.loss = model(image_embed.to(self.device), y_input, y_label, self.downstream_finetune)\n",
    "                    train_loss_epoch.append(self.loss.detach().cpu().item())\n",
    "\n",
    "                    # backprop and update the parameters\n",
    "                    model.zero_grad(set_to_none=True)\n",
    "                    self.loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), config.grad_norm_clip)\n",
    "                    self.optimizer.step()\n",
    "                    pbar.update(1)\n",
    "                    del x, y_input, y_label\n",
    "\n",
    "                print('Training Loss is : {}'.format(sum(train_loss_epoch)/len(train_loss_epoch)))\n",
    "                train_loss_set.append(sum(train_loss_epoch)/len(train_loss_epoch))\n",
    "            \n",
    "            print('start_validation')    \n",
    "            model.eval()\n",
    "            cnn_model.eval()  \n",
    "            valid_loss_epoch = []\n",
    "            for x, y_input, y_label in self.valid_loader:\n",
    "                # forward the model\n",
    "                x = x.type(torch.FloatTensor).to(device)\n",
    "                image_embed = cnn_model(x)\n",
    "                logits, loss = model(image_embed.to(self.device), y_input, y_label, self.downstream_finetune)\n",
    "                valid_loss_epoch.append(loss.detach().cpu().item())\n",
    "                del x, y_input, y_label\n",
    "                \n",
    "            current_valid_loss = sum(valid_loss_epoch)/len(valid_loss_epoch)\n",
    "            print('Validation Loss is : {}'.format(current_valid_loss))              \n",
    "            \n",
    "            #save the checkpoint if the current validation loss is better than all previous epochs   \n",
    "            if len(valid_loss_set) > 0 and current_valid_loss < min(valid_loss_set):\n",
    "                torch.save(model.state_dict(), './saved_checkpoints/best_transformer.pt')\n",
    "                torch.save(cnn_model.state_dict(), './saved_checkpoints/best_cnn.pt')\n",
    "                print('saving checkpoints')\n",
    "            #stop training if the validation loss increases for two consecutive epochs     \n",
    "            if len(valid_loss_set) > 2 and current_valid_loss > valid_loss_set[-1] and valid_loss_set[-1] > valid_loss_set[-2]:\n",
    "                valid_loss_set.append(current_valid_loss)  \n",
    "                break           \n",
    "            else:\n",
    "                valid_loss_set.append(current_valid_loss)\n",
    "        \n",
    "        return train_loss_set, valid_loss_set, epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6e29acb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on device cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\zixua/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable params: 41315772\n",
      "Epoch 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:22<00:00,  5.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 8.713794231414795\n",
      "start_validation\n",
      "Validation Loss is : 5.1838845941755505\n",
      "Epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:19<00:00,  6.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 2.600729073935408\n",
      "start_validation\n",
      "Validation Loss is : 1.0569030907418993\n",
      "saving checkpoints\n",
      "Epoch 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:18<00:00,  6.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.7998156591159541\n",
      "start_validation\n",
      "Validation Loss is : 0.6961187952094607\n",
      "saving checkpoints\n",
      "Epoch 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:29<00:00,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.607119265126019\n",
      "start_validation\n",
      "Validation Loss is : 0.6032332364055846\n",
      "saving checkpoints\n",
      "Epoch 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:25<00:00,  4.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.5388626899661088\n",
      "start_validation\n",
      "Validation Loss is : 0.5614820238616731\n",
      "saving checkpoints\n",
      "Epoch 5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:19<00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.5067223034253935\n",
      "start_validation\n",
      "Validation Loss is : 0.541541596253713\n",
      "saving checkpoints\n",
      "Epoch 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:19<00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.4873194040321722\n",
      "start_validation\n",
      "Validation Loss is : 0.5353723929988013\n",
      "saving checkpoints\n",
      "Epoch 7:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:20<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.47486930189093923\n",
      "start_validation\n",
      "Validation Loss is : 0.5227817495663961\n",
      "saving checkpoints\n",
      "Epoch 8:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:21<00:00,  5.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.4686266937391545\n",
      "start_validation\n",
      "Validation Loss is : 0.5182590203152763\n",
      "saving checkpoints\n",
      "Epoch 9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:20<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.4596851836375105\n",
      "start_validation\n",
      "Validation Loss is : 0.5211980922354592\n",
      "Epoch 10:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:20<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.45407295348198434\n",
      "start_validation\n",
      "Validation Loss is : 0.5149799635012945\n",
      "saving checkpoints\n",
      "Epoch 11:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:19<00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.45413658749766467\n",
      "start_validation\n",
      "Validation Loss is : 0.5127036621173223\n",
      "saving checkpoints\n",
      "Epoch 12:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:19<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.4508289416146472\n",
      "start_validation\n",
      "Validation Loss is : 0.5109417024585936\n",
      "saving checkpoints\n",
      "Epoch 13:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:20<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.4396481344370338\n",
      "start_validation\n",
      "Validation Loss is : 0.5096800790892707\n",
      "saving checkpoints\n",
      "Epoch 14:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:20<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.44176979302390806\n",
      "start_validation\n",
      "Validation Loss is : 0.5052696433332231\n",
      "saving checkpoints\n",
      "Epoch 15:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:19<00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.4375094420057002\n",
      "start_validation\n",
      "Validation Loss is : 0.5092596842183007\n",
      "Epoch 16:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:20<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.4404128722059048\n",
      "start_validation\n",
      "Validation Loss is : 0.5072492758433024\n",
      "Epoch 17:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:20<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.4333066644707346\n",
      "start_validation\n",
      "Validation Loss is : 0.5045288569397397\n",
      "saving checkpoints\n",
      "Epoch 18:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:20<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.4346936291795436\n",
      "start_validation\n",
      "Validation Loss is : 0.5076532479789522\n",
      "Epoch 19:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:20<00:00,  6.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.42962090465111463\n",
      "start_validation\n",
      "Validation Loss is : 0.5006386372778151\n",
      "saving checkpoints\n",
      "Epoch 20:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:20<00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.4297116134709459\n",
      "start_validation\n",
      "Validation Loss is : 0.4990292141834895\n",
      "saving checkpoints\n",
      "Epoch 21:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:20<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.4302920602201446\n",
      "start_validation\n",
      "Validation Loss is : 0.4991511752208074\n",
      "Epoch 22:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:20<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.42423823984657844\n",
      "start_validation\n",
      "Validation Loss is : 0.4984959049357308\n",
      "saving checkpoints\n",
      "Epoch 23:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:20<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.4279930574622581\n",
      "start_validation\n",
      "Validation Loss is : 0.49915242691834766\n",
      "Epoch 24:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:20<00:00,  6.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.42016021870985265\n",
      "start_validation\n",
      "Validation Loss is : 0.5005278471443388\n"
     ]
    }
   ],
   "source": [
    "#start training\n",
    "train_config = Trainer.get_default_config()\n",
    "trainer = Trainer(train_config, model, train_loader, valid_loader, epochs, downstream_finetune = False)\n",
    "\n",
    "# Train!\n",
    "train_loss_set, valid_loss_set, epoch = trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1dea6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot results\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18,8))\n",
    "epoch_values = list(range(0, epoch+1, 1))\n",
    "\n",
    "ax1.plot(epoch_values, train_loss_set)\n",
    "ax2.plot(epoch_values, valid_loss_set)\n",
    "\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Average Train Loss')    \n",
    "ax1.set_title('Average Train Loss vs. Epochs')\n",
    "\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Average Validation Loss')    \n",
    "ax2.set_title('Average Validation Loss vs. Epochs')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8574dc33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
