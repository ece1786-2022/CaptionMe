{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eca7ed2d",
   "metadata": {},
   "source": [
    "# Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbf01e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchtext\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import math\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from mingpt.utils import CfgNode as CN\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ac7cf1",
   "metadata": {},
   "source": [
    "# Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31db5ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path_train = '../All_Data/annotations_train.csv'\n",
    "image_path_train = '../All_Data/train'\n",
    "csv_path_valid = '../All_Data/annotations_valid.csv'\n",
    "image_path_valid = '../All_Data/valid'\n",
    "batch_size = 8\n",
    "epochs = 50\n",
    "n_embed = 100\n",
    "glove = torchtext.vocab.GloVe(name=\"6B\",dim=n_embed) # embedding size = 100  \n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96f09c2",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc46f0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_Dataset(Dataset):\n",
    "    def __init__(self, image_folder_path, vocab, csv_path, custom_transforms):\n",
    "        self.image_folder_path = image_folder_path\n",
    "        annotations = pd.read_csv(csv_path)\n",
    "        self.captions = np.array(annotations['captions'])\n",
    "        self.image_names = np.array(annotations['file_directory'])    \n",
    "        self.custom_transforms = custom_transforms\n",
    "        self.replace_dict = {'Cockapoo':'parrot', 'Dalmation':'dalmatian', 'Bluetick':'bluebonnet', 'Perenees':'pere', 'Groenendael':'goren', 'Shih-Tzu':'shih', 'Shar_Pei':'shar', 'Komondor':'komon'}\n",
    "        self.vocab = vocab\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.captions)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_full_name = self.image_folder_path + '/' + self.image_names[idx]\n",
    "        x = Image.open(image_full_name)\n",
    "        if self.custom_transforms is not None:\n",
    "            x = self.custom_transforms(x)\n",
    "#             x = x.permute(1,2,0)\n",
    "        ground_truth_cap = self.captions[idx]\n",
    "        V = len(self.vocab.vectors)\n",
    "        L = ground_truth_cap.split()\n",
    "        for i, word in enumerate (L):\n",
    "            if word in self.replace_dict.keys():\n",
    "                L[i] = self.replace_dict[word]\n",
    "                \n",
    "        tokenized_caption = torch.tensor([self.vocab.stoi.get(w.lower(), V-1) for w in L])  # Use the last word in the vocab as the \"out-of-vocabulary\" token\n",
    "        if V-1 in tokenized_caption:\n",
    "            print('Wrong Labelling')\n",
    "#         print(image_full_name, ground_truth_cap)        \n",
    "        return x, tokenized_caption\n",
    "    \n",
    "    def get_vocab_size(self):\n",
    "        return len(self.vocab.vectors)  \n",
    "    \n",
    "    def get_block_size(self):\n",
    "        all_captions_len = []\n",
    "        for i in range(len(self.captions)):\n",
    "            all_captions_len.append(len(self.captions[i].split()))\n",
    "        return max(all_captions_len)+1\n",
    "    \n",
    "train_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(224),\n",
    "    torchvision.transforms.RandomHorizontalFlip(p=0.3),\n",
    "    torchvision.transforms.RandomRotation(degrees=10),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "valid_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(224),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "def lm_collate_fn(batch, device):\n",
    "    x = [item[0] for item in batch]  \n",
    "    y_input = [item[1][:-1] for item in batch]  \n",
    "    y_label = [item[1] for item in batch]\n",
    "    maxlen_input = max([len(s) for s in y_input])\n",
    "    maxlen_label = max([len(s) for s in y_label])\n",
    "    padding_value = glove.stoi.get('unk')\n",
    "    #x from first word to the second last word, y from second word to the last word\n",
    "    input_cap, label_cap = [], []\n",
    "    for sy_i, sy_l in zip(y_input, y_label):\n",
    "        input_cap.append(torch.cat([sy_i, torch.ones(maxlen_input - len(sy_i))*padding_value]))\n",
    "        label_cap.append(torch.cat([sy_l, torch.ones(maxlen_label - len(sy_l))*padding_value]))\n",
    "    return torch.stack(x).long().to(device), torch.stack(input_cap).long().to(device), torch.stack(label_cap).long().to(device)\n",
    "  \n",
    "train_dataset = Custom_Dataset(image_path_train, glove, csv_path_train, train_transforms)\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn = lambda batch: lm_collate_fn(batch, device))\n",
    "\n",
    "valid_dataset = Custom_Dataset(image_path_valid, glove, csv_path_valid, valid_transforms)\n",
    "batch_size = 32\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, collate_fn = lambda batch: lm_collate_fn(batch, device))\n",
    "\n",
    "vocab_size = train_dataset.get_vocab_size()\n",
    "block_size = train_dataset.get_block_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b624598",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "018500df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.py\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "class NewGELU(nn.Module):\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (x + 0.044715 * torch.pow(x, 3.0))))\n",
    "\n",
    "class CausalSelfAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.n_embd % config.n_head == 0\n",
    "        # key, query, value projections for all heads, but in a batch\n",
    "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd)\n",
    "        # output projection\n",
    "        self.c_proj = nn.Linear(config.n_embd, config.n_embd)\n",
    "        # regularization\n",
    "        self.attn_dropout = nn.Dropout(config.attn_pdrop)\n",
    "        self.resid_dropout = nn.Dropout(config.resid_pdrop)\n",
    "        # causal mask to ensure that attention is only applied to the left in the input sequence\n",
    "        self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
    "                                     .view(1, 1, config.block_size, config.block_size))\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.n_embd\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n",
    "\n",
    "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
    "        q, k ,v  = self.c_attn(x).split(self.n_embd, dim=2)\n",
    "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "\n",
    "        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n",
    "        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
    "        att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n",
    "        att = F.softmax(att, dim=-1)\n",
    "        att = self.attn_dropout(att)\n",
    "        y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n",
    "\n",
    "        # output projection\n",
    "        y = self.resid_dropout(self.c_proj(y))\n",
    "        return y\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln_1 = nn.LayerNorm(config.n_embd)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.ln_2 = nn.LayerNorm(config.n_embd)\n",
    "        self.mlp = nn.ModuleDict(dict(\n",
    "            c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd),\n",
    "            c_proj  = nn.Linear(4 * config.n_embd, config.n_embd),\n",
    "            act     = NewGELU(),\n",
    "            dropout = nn.Dropout(config.resid_pdrop),\n",
    "        ))\n",
    "        m = self.mlp\n",
    "        self.mlpf = lambda x: m.dropout(m.c_proj(m.act(m.c_fc(x)))) # MLP forward\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x.shape = (batch, sent len, embedding)\n",
    "        x = x + self.attn(self.ln_1(x))\n",
    "        x = x + self.mlpf(self.ln_2(x))\n",
    "        return x\n",
    "\n",
    "class GPT(nn.Module):\n",
    "    \"\"\" GPT Language Model \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def get_default_config():\n",
    "        C = CN()\n",
    "        # either model_type or (n_layer, n_head, n_embd) must be given in the config\n",
    "        C.model_type = 'gpt'\n",
    "        C.n_layer = None\n",
    "        C.n_head = None\n",
    "        C.n_embd =  None\n",
    "        # these options must be filled in externally\n",
    "        C.vocab_size = None\n",
    "        C.block_size = None\n",
    "        # dropout hyperparameters\n",
    "        C.embd_pdrop = 0.1\n",
    "        C.resid_pdrop = 0.1\n",
    "        C.attn_pdrop = 0.1\n",
    "        return C\n",
    "\n",
    "    def __init__(self, config, vocab):\n",
    "        super().__init__()\n",
    "        assert config.vocab_size is not None\n",
    "        assert config.block_size is not None\n",
    "        self.block_size = config.block_size\n",
    "\n",
    "        type_given = config.model_type is not None\n",
    "        params_given = all([config.n_layer is not None, config.n_head is not None, config.n_embd is not None])\n",
    "        assert type_given ^ params_given # exactly one of these (XOR)\n",
    "        if type_given:\n",
    "            # translate from model_type to detailed configuration\n",
    "            config.merge_from_dict({\n",
    "                # names follow the huggingface naming conventions\n",
    "                # GPT-1\n",
    "                'openai-gpt':   dict(n_layer=12, n_head=12, n_embd=768),  # 117M params\n",
    "                # GPT-2 configs\n",
    "                'gpt2':         dict(n_layer=12, n_head=12, n_embd=768),  # 124M params\n",
    "                'gpt2-medium':  dict(n_layer=24, n_head=16, n_embd=1024), # 350M params\n",
    "                'gpt2-large':   dict(n_layer=36, n_head=20, n_embd=1280), # 774M params\n",
    "                'gpt2-xl':      dict(n_layer=48, n_head=25, n_embd=1600), # 1558M params\n",
    "                # Gophers\n",
    "                'gopher-44m':   dict(n_layer=8, n_head=16, n_embd=512),\n",
    "                # (there are a number more...)\n",
    "                # I made these tiny models up\n",
    "                'gpt-mini':     dict(n_layer=5, n_head=5, n_embd=n_embed),\n",
    "                'gpt-micro':    dict(n_layer=4, n_head=4, n_embd=128),\n",
    "                'gpt-nano':     dict(n_layer=3, n_head=3, n_embd=48),\n",
    "            }[config.model_type])\n",
    "\n",
    "        #wte is embedding for words\n",
    "        #wpe is embedding for positions\n",
    "        self.transformer = nn.ModuleDict(dict(\n",
    "            wte = nn.Embedding.from_pretrained(vocab.vectors, freeze = True),\n",
    "            wpe = nn.Embedding(config.block_size, config.n_embd),\n",
    "            drop = nn.Dropout(config.embd_pdrop),\n",
    "            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
    "            ln_f = nn.LayerNorm(config.n_embd),\n",
    "        ))\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "\n",
    "        # init all weights, and apply a special scaled init to the residual projections, per GPT-2 paper\n",
    "        self.apply(self._init_weights)\n",
    "        for pn, p in self.named_parameters():\n",
    "            if pn.endswith('c_proj.weight'):\n",
    "                torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2 * config.n_layer))\n",
    "\n",
    "        # report number of parameters (note we don't count the decoder parameters in lm_head)\n",
    "        n_params = sum(p.numel() for p in self.transformer.parameters())\n",
    "        print(\"number of parameters: %.2fM\" % (n_params/1e6,))\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            torch.nn.init.zeros_(module.bias)\n",
    "            torch.nn.init.ones_(module.weight)\n",
    "\n",
    "    def configure_optimizers(self, train_config, cnn_model_params):\n",
    "        # separate out all parameters to those that will and won't experience regularizing weight decay\n",
    "        decay = set()\n",
    "        no_decay = set()\n",
    "        whitelist_weight_modules = (torch.nn.Linear, )\n",
    "        blacklist_weight_modules = (torch.nn.LayerNorm, torch.nn.Embedding)\n",
    "        for mn, m in self.named_modules():\n",
    "            for pn, p in m.named_parameters():\n",
    "                fpn = '%s.%s' % (mn, pn) if mn else pn # full param name\n",
    "                # random note: because named_modules and named_parameters are recursive\n",
    "                # we will see the same tensors p many many times. but doing it this way\n",
    "                # allows us to know which parent module any tensor p belongs to...\n",
    "                if pn.endswith('bias'):\n",
    "                    # all biases will not be decayed\n",
    "                    no_decay.add(fpn)\n",
    "                elif pn.endswith('weight') and isinstance(m, whitelist_weight_modules):\n",
    "                    # weights of whitelist modules will be weight decayed\n",
    "                    decay.add(fpn)\n",
    "                elif pn.endswith('weight') and isinstance(m, blacklist_weight_modules):\n",
    "                    # weights of blacklist modules will NOT be weight decayed\n",
    "                    no_decay.add(fpn)\n",
    "\n",
    "        # validate that we considered every parameter\n",
    "        param_dict = {pn: p for pn, p in self.named_parameters()}\n",
    "        inter_params = decay & no_decay\n",
    "        union_params = decay | no_decay\n",
    "        assert len(inter_params) == 0, \"parameters %s made it into both decay/no_decay sets!\" % (str(inter_params), )\n",
    "        assert len(param_dict.keys() - union_params) == 0, \"parameters %s were not separated into either decay/no_decay set!\" \\\n",
    "                                                    % (str(param_dict.keys() - union_params), )\n",
    "        if cnn_model_params is not None:\n",
    "            # create the pytorch optimizer object\n",
    "            optim_groups = [\n",
    "                {\"params\": [param_dict[pn] for pn in sorted(list(decay))], \"weight_decay\": train_config.weight_decay},\n",
    "                {\"params\": [param_dict[pn] for pn in sorted(list(no_decay))], \"weight_decay\": 0.0},\n",
    "                {\"params\": cnn_model_params,'lr': 3e-5}\n",
    "            ]\n",
    "            \n",
    "            n_parameters_transformer = sum(p.numel()\n",
    "               for p in self.parameters() if p.requires_grad)\n",
    "            n_parameters_cnn = sum(p.numel()\n",
    "                           for p in cnn_model_params if p.requires_grad)\n",
    "            print(f\"Number of trainable params: {n_parameters_transformer + n_parameters_cnn}\")\n",
    "        else:\n",
    "            # create the pytorch optimizer object\n",
    "            optim_groups = [\n",
    "                {\"params\": [param_dict[pn] for pn in sorted(list(decay))], \"weight_decay\": train_config.weight_decay},\n",
    "                {\"params\": [param_dict[pn] for pn in sorted(list(no_decay))], \"weight_decay\": 0.0}\n",
    "            ]  \n",
    "        \n",
    "            n_parameters_transformer = sum(p.numel()\n",
    "                           for p in self.parameters() if p.requires_grad)\n",
    "            print(f\"Number of trainable params: {n_parameters_transformer}\")\n",
    "        \n",
    "        optimizer = torch.optim.AdamW(optim_groups, lr=train_config.learning_rate, betas=train_config.betas)\n",
    "        return optimizer\n",
    "\n",
    "    def forward(self, image_embed, idx=None, targets=None, finetune_classify=False):\n",
    "\n",
    "        device = image_embed.device\n",
    "  \n",
    "        if idx is not None:\n",
    "            b, t = idx.size()\n",
    "            assert t <= self.block_size, f\"Cannot forwarnd sequence of length {t}, block size is only {self.block_size}\"\n",
    "            pos = torch.arange(0, t+1, dtype=torch.long, device=device).unsqueeze(0) # shape (1, t)\n",
    "\n",
    "            # forward the GPT model itself\n",
    "            tok_emb = self.transformer.wte(idx) # token embeddings of shape (b, t, n_embd)\n",
    "            tok_emb = torch.cat((image_embed.unsqueeze(1), tok_emb), 1)\n",
    "          \n",
    "        else:\n",
    "            pos = torch.arange(0, 1, dtype=torch.long, device=device).unsqueeze(0) # shape (1, t)\n",
    "            tok_emb = image_embed.unsqueeze(1)   \n",
    "        pos_emb = self.transformer.wpe(pos) # position embeddings of shape (1, t, n_embd)\n",
    "        \n",
    "        assert tok_emb[0].shape == pos_emb[0].shape, f\"wrong token or position embedding\"\n",
    "        x = self.transformer.drop(tok_emb + pos_emb)\n",
    "        for block in self.transformer.h:\n",
    "            x = block(x)\n",
    "        x = self.transformer.ln_f(x)\n",
    "        #x.shape = (batch, sentence len, embedding)\n",
    "        if not finetune_classify:\n",
    "            # LM forward procedure\n",
    "            logits = self.lm_head(x)\n",
    "        else:\n",
    "            # Finetune classify procedure\n",
    "            print('error')\n",
    "            return\n",
    "            \n",
    "        # if we are given some desired targets also calculate the loss\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
    "        return logits, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dbf39fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 40.61M\n"
     ]
    }
   ],
   "source": [
    "# set up model configurations\n",
    "model_config = GPT.get_default_config()\n",
    "model_config.model_type = 'gpt-mini'\n",
    "model_config.vocab_size = vocab_size\n",
    "#block_size is a max sentence length in dataset\n",
    "model_config.block_size = block_size\n",
    "model = GPT(model_config, glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d25c008",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fca9c92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "\n",
    "    @staticmethod\n",
    "    def get_default_config():\n",
    "        C = CN()\n",
    "        # device to train on\n",
    "        C.device = 'auto'\n",
    "        # dataloder parameters\n",
    "        C.num_workers = 4\n",
    "        # optimizer parameters\n",
    "        C.max_iters = None\n",
    "        C.batch_size = 64\n",
    "        C.learning_rate = 3e-4\n",
    "        C.betas = (0.9, 0.95)\n",
    "        C.weight_decay = 0.1 # only applied on matmul weights\n",
    "        C.grad_norm_clip = 1.0\n",
    "        return C\n",
    "\n",
    "    def __init__(self, config, model, train_loader, valid_loader, epochs, downstream_finetune = False):\n",
    "        self.config = config\n",
    "        self.model = model\n",
    "        self.optimizer = None\n",
    "        self.train_loader = train_loader\n",
    "        self.valid_loader = valid_loader\n",
    "        self.epochs = epochs\n",
    "        self.callbacks = defaultdict(list)\n",
    "        self.downstream_finetune = False\n",
    "        # determine the device we'll train on\n",
    "        if config.device == 'auto':\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = config.device\n",
    "        self.model = self.model.to(self.device)\n",
    "        print(\"running on device\", self.device)\n",
    "\n",
    "        # variables that will be assigned to trainer class later for logging and etc\n",
    "        self.iter_time = 0.0\n",
    "        self.iter_dt = 0.0\n",
    "\n",
    "    def add_callback(self, onevent: str, callback):\n",
    "        self.callbacks[onevent].append(callback)\n",
    "\n",
    "    def set_callback(self, onevent: str, callback):\n",
    "        self.callbacks[onevent] = [callback]\n",
    "\n",
    "    def trigger_callbacks(self, onevent: str):\n",
    "        for callback in self.callbacks.get(onevent, []):\n",
    "            callback(self)\n",
    "\n",
    "    def run(self):\n",
    "        model, config = self.model, self.config\n",
    "        cnn_model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=True,)\n",
    "        for param in cnn_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        cnn_model.classifier = nn.Sequential(nn.Linear(1280, 512),\n",
    "                                            nn.ReLU(),\n",
    "                                            nn.Dropout(0.2),\n",
    "                                            nn.Linear(512, n_embed))\n",
    "        cnn_model = cnn_model.to(device)\n",
    "        # setup the optimizer\n",
    "        self.optimizer = model.configure_optimizers(config, cnn_model.parameters())\n",
    "        train_loss_set = []\n",
    "        valid_loss_set = []\n",
    "        # setup the dataloader     \n",
    "        for epoch in range(self.epochs):\n",
    "            print('Epoch ' + str(epoch) + ':')\n",
    "            model.train()\n",
    "            cnn_model.train()\n",
    "            train_loss_epoch = []\n",
    "            \n",
    "            with tqdm.tqdm(total=len(self.train_loader)) as pbar:\n",
    "                #train model and calculate training loss\n",
    "                for x, y_input, y_label in self.train_loader:\n",
    "                    # forward the model\n",
    "                    x = x.type(torch.FloatTensor).to(device)\n",
    "                    image_embed = cnn_model(x)\n",
    "                    logits, self.loss = model(image_embed.to(self.device), y_input, y_label, self.downstream_finetune)\n",
    "                    train_loss_epoch.append(self.loss.detach().cpu().item())\n",
    "\n",
    "                    # backprop and update the parameters\n",
    "                    model.zero_grad(set_to_none=True)\n",
    "                    self.loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), config.grad_norm_clip)\n",
    "                    self.optimizer.step()\n",
    "                    pbar.update(1)\n",
    "                    del x, y_input, y_label\n",
    "\n",
    "                print('Training Loss is : {}'.format(sum(train_loss_epoch)/len(train_loss_epoch)))\n",
    "                train_loss_set.append(sum(train_loss_epoch)/len(train_loss_epoch))\n",
    "            \n",
    "            print('start_validation')    \n",
    "            model.eval()\n",
    "            cnn_model.eval()  \n",
    "            valid_loss_epoch = []\n",
    "            for x, y_input, y_label in self.valid_loader:\n",
    "                # forward the model\n",
    "                x = x.type(torch.FloatTensor).to(device)\n",
    "                image_embed = cnn_model(x)\n",
    "                logits, loss = model(image_embed.to(self.device), y_input, y_label, self.downstream_finetune)\n",
    "                valid_loss_epoch.append(loss.detach().cpu().item())\n",
    "                del x, y_input, y_label\n",
    "                \n",
    "            current_valid_loss = sum(valid_loss_epoch)/len(valid_loss_epoch)\n",
    "            print('Validation Loss is : {}'.format(current_valid_loss))              \n",
    "            \n",
    "            #save the checkpoint if the current validation loss is better than all previous epochs   \n",
    "            if len(valid_loss_set) > 0 and current_valid_loss < min(valid_loss_set):\n",
    "                torch.save(model.state_dict(), './saved_checkpoints/best_transformer.pt')\n",
    "                torch.save(cnn_model.state_dict(), './saved_checkpoints/best_cnn.pt')\n",
    "                print('saving checkpoints')\n",
    "            #stop training if the validation loss increases for two consecutive epochs     \n",
    "            if len(valid_loss_set) > 2 and current_valid_loss > valid_loss_set[-1] and valid_loss_set[-1] > valid_loss_set[-2]:\n",
    "                valid_loss_set.append(current_valid_loss)  \n",
    "                break           \n",
    "            else:\n",
    "                valid_loss_set.append(current_valid_loss)\n",
    "        \n",
    "        return train_loss_set, valid_loss_set, epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6e29acb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\zixua/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on device cuda\n",
      "Number of trainable params: 41315672\n",
      "Epoch 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:25<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 8.761079357891548\n",
      "start_validation\n",
      "Validation Loss is : 5.287910381952922\n",
      "Epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:18<00:00,  6.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 2.642167899666763\n",
      "start_validation\n",
      "Validation Loss is : 1.0627918706999884\n",
      "saving checkpoints\n",
      "Epoch 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:19<00:00,  6.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.8202161842245397\n",
      "start_validation\n",
      "Validation Loss is : 0.7077921662065718\n",
      "saving checkpoints\n",
      "Epoch 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:18<00:00,  6.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.6431929919777847\n",
      "start_validation\n",
      "Validation Loss is : 0.6249565283457438\n",
      "saving checkpoints\n",
      "Epoch 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:18<00:00,  6.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.5781257748603821\n",
      "start_validation\n",
      "Validation Loss is : 0.5832648310396407\n",
      "saving checkpoints\n",
      "Epoch 5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:19<00:00,  6.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.5459966371214486\n",
      "start_validation\n",
      "Validation Loss is : 0.5646112296316359\n",
      "saving checkpoints\n",
      "Epoch 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:18<00:00,  6.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.5240220572890305\n",
      "start_validation\n",
      "Validation Loss is : 0.5567914297183355\n",
      "saving checkpoints\n",
      "Epoch 7:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:19<00:00,  6.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.5105230103178722\n",
      "start_validation\n",
      "Validation Loss is : 0.5421103719207976\n",
      "saving checkpoints\n",
      "Epoch 8:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:19<00:00,  6.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.5003869557768349\n",
      "start_validation\n",
      "Validation Loss is : 0.5375668207804362\n",
      "saving checkpoints\n",
      "Epoch 9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:19<00:00,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.49338170886039734\n",
      "start_validation\n",
      "Validation Loss is : 0.5347454332643085\n",
      "saving checkpoints\n",
      "Epoch 10:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:20<00:00,  6.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.4888110720529789\n",
      "start_validation\n",
      "Validation Loss is : 0.5283694432841407\n",
      "saving checkpoints\n",
      "Epoch 11:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:19<00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.4849257512790401\n",
      "start_validation\n",
      "Validation Loss is : 0.5308853321605258\n",
      "Epoch 12:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:20<00:00,  6.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.47929219453315425\n",
      "start_validation\n",
      "Validation Loss is : 0.5228111512131162\n",
      "saving checkpoints\n",
      "Epoch 13:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:20<00:00,  6.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.4748599737640319\n",
      "start_validation\n",
      "Validation Loss is : 0.5258123394515779\n",
      "Epoch 14:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:19<00:00,  6.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.4753376843968058\n",
      "start_validation\n",
      "Validation Loss is : 0.5256643096605936\n",
      "Epoch 15:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:19<00:00,  6.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.4726841340704662\n",
      "start_validation\n",
      "Validation Loss is : 0.5217767639292611\n",
      "saving checkpoints\n",
      "Epoch 16:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:19<00:00,  6.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.4684046281547081\n",
      "start_validation\n",
      "Validation Loss is : 0.5167866564459271\n",
      "saving checkpoints\n",
      "Epoch 17:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:19<00:00,  6.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.46595893133946553\n",
      "start_validation\n",
      "Validation Loss is : 0.5181404600540797\n",
      "Epoch 18:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 123/123 [00:19<00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is : 0.4641178625870526\n",
      "start_validation\n",
      "Validation Loss is : 0.5233965300851398\n"
     ]
    }
   ],
   "source": [
    "#start training\n",
    "train_config = Trainer.get_default_config()\n",
    "trainer = Trainer(train_config, model, train_loader, valid_loader, epochs, downstream_finetune = False)\n",
    "\n",
    "# Train!\n",
    "train_loss_set, valid_loss_set, epoch = trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1dea6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot results\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18,8))\n",
    "epoch_values = list(range(0, epoch+1, 1))\n",
    "\n",
    "ax1.plot(epoch_values, train_loss_set)\n",
    "ax2.plot(epoch_values, valid_loss_set)\n",
    "\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Average Train Loss')    \n",
    "ax1.set_title('Average Train Loss vs. Epochs')\n",
    "\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Average Validation Loss')    \n",
    "ax2.set_title('Average Validation Loss vs. Epochs')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8574dc33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
